{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\anaconda\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\anaconda\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\anaconda\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\anaconda\\lib\\site-packages (from pymorphy2) (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('litw-win.txt', 'r', encoding = 'cp1251') as f:\n",
    "    words = [line.split()[-1] for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in c:\\anaconda\\lib\\site-packages (0.20.9)\n",
      "Requirement already satisfied: Levenshtein==0.20.9 in c:\\anaconda\\lib\\site-packages (from python-Levenshtein) (0.20.9)\n",
      "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in c:\\anaconda\\lib\\site-packages (from Levenshtein==0.20.9->python-Levenshtein) (2.15.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as lev\n",
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance(text, words)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Считайте слова из файла litw-win.txt и запишите их в список words. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "SnowballStemmer.languages\n",
    "import re\n",
    "snb_stemmer_ru = SnowballStemmer('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "счита\n",
      "слов\n",
      "из\n",
      "файл\n",
      "litw-win.txt\n",
      "и\n",
      "запиш\n",
      "их\n",
      "в\n",
      "список\n",
      "words.\n",
      "в\n",
      "зада\n",
      "предложен\n",
      "исправьт\n",
      "все\n",
      "опечатки,\n",
      "замен\n",
      "слов\n",
      "с\n",
      "опечатк\n",
      "на\n",
      "ближайш\n",
      "(в\n",
      "смысл\n",
      "расстоян\n",
      "левенштейна)\n",
      "к\n",
      "ним\n",
      "слов\n",
      "из\n",
      "списк\n",
      "words.\n",
      "считайте,\n",
      "что\n",
      "в\n",
      "слов\n",
      "ест\n",
      "опечатка,\n",
      "есл\n",
      "дан\n",
      "слов\n",
      "не\n",
      "содерж\n",
      "в\n",
      "списк\n",
      "words.\n"
     ]
    }
   ],
   "source": [
    "import nltk   # стемминг\n",
    "ps = SnowballStemmer('russian')\n",
    "for i in text:\n",
    "    print(ps.stem(i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "считать\n",
      "слово\n",
      "из\n",
      "файл\n",
      "litw-win.txt\n",
      "и\n",
      "записать\n",
      "они\n",
      "в\n",
      "список\n",
      "words.\n",
      "в\n",
      "задать\n",
      "предложение\n",
      "исправить\n",
      "всё\n",
      "опечатки,\n",
      "заменить\n",
      "слово\n",
      "с\n",
      "опечатка\n",
      "на\n",
      "близкий\n",
      "(в\n",
      "смысл\n",
      "расстояние\n",
      "левенштейна)\n",
      "к\n",
      "они\n",
      "слово\n",
      "из\n",
      "список\n",
      "words.\n",
      "считайте,\n",
      "что\n",
      "в\n",
      "слово\n",
      "есть\n",
      "опечатка,\n",
      "если\n",
      "данный\n",
      "слово\n",
      "не\n",
      "содержаться\n",
      "в\n",
      "список\n",
      "words.\n"
     ]
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "for i in text:\n",
    "    print(morph.parse(i)[0].normalized.word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['litw',\n",
       " 'txt',\n",
       " 'win',\n",
       " 'words',\n",
       " 'ближайшие',\n",
       " 'все',\n",
       " 'данное',\n",
       " 'если',\n",
       " 'есть',\n",
       " 'заданном',\n",
       " 'заменив',\n",
       " 'запишите',\n",
       " 'из',\n",
       " 'исправьте',\n",
       " 'их',\n",
       " 'левенштейна',\n",
       " 'на',\n",
       " 'не',\n",
       " 'ним',\n",
       " 'опечатка',\n",
       " 'опечатками',\n",
       " 'опечатки',\n",
       " 'предложении',\n",
       " 'расстояния',\n",
       " 'слова',\n",
       " 'слове',\n",
       " 'слово',\n",
       " 'смысле',\n",
       " 'содержится',\n",
       " 'списка',\n",
       " 'списке',\n",
       " 'список',\n",
       " 'считайте',\n",
       " 'файла',\n",
       " 'что']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "text = 'Считайте слова из файла litw-win.txt и запишите их в список words. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.'.split()\n",
    "cv = CountVectorizer()\n",
    "# векторизуем корпус:\n",
    "corpus_cv = cv.fit_transform(text)\n",
    "corpus_cv\n",
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_ar = corpus_cv.toarray()\n",
    "cv_ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>preprocessed_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i can t believe it s spinach</td>\n",
       "      <td>these were so go it surprised even me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>italian  gut busters</td>\n",
       "      <td>my sisterinlaw made these for us at a family g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>love is in the air  beef fondue   sauces</td>\n",
       "      <td>i think a fondue is a very romantic casual din...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      name  \\\n",
       "0           0     george s at the cove  black bean soup   \n",
       "1           1        healthy for them  yogurt popsicles   \n",
       "2           2              i can t believe it s spinach   \n",
       "3           3                      italian  gut busters   \n",
       "4           4  love is in the air  beef fondue   sauces   \n",
       "\n",
       "                           preprocessed_descriptions  \n",
       "0  an original recipe created by chef scott meska...  \n",
       "1  my children and their friends ask for my homem...  \n",
       "2              these were so go it surprised even me  \n",
       "3  my sisterinlaw made these for us at a family g...  \n",
       "4  i think a fondue is a very romantic casual din...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('preprocessed_descriptions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'devis',\n",
       " 'mircaz',\n",
       " 'ortegas',\n",
       " '232706',\n",
       " 'liners',\n",
       " 'lights',\n",
       " 'tray',\n",
       " 'bedroom',\n",
       " 'distinctly',\n",
       " 'timesuggestion',\n",
       " 'goodnothing',\n",
       " 'forewarned',\n",
       " 'plantains',\n",
       " 'anticipation',\n",
       " 'pastelike',\n",
       " 'falliano',\n",
       " 'settlement',\n",
       " 'turned',\n",
       " 'httpwwwfoodcomarticlestrangerthingsvalentinesday306',\n",
       " 'hummous',\n",
       " 'ballpark',\n",
       " 'rechecked',\n",
       " 'traysthis',\n",
       " 'goodor',\n",
       " 'swears',\n",
       " 'ream',\n",
       " 'db',\n",
       " 'band',\n",
       " 'wher',\n",
       " 'cornmealflavored',\n",
       " 'cucumber',\n",
       " 'breakstone',\n",
       " 'premixed',\n",
       " 'cirque',\n",
       " 'intelligent',\n",
       " 'bhunni',\n",
       " 'aspic',\n",
       " 'responders',\n",
       " 'featuringeverything',\n",
       " 'hancock',\n",
       " 'watchers1996',\n",
       " 'eastas',\n",
       " 'slight',\n",
       " 'betting',\n",
       " 'eateries',\n",
       " 'carving',\n",
       " 'avgolemono',\n",
       " 'malanga',\n",
       " 'recipeslice',\n",
       " 'archers',\n",
       " 'murg',\n",
       " 'facil',\n",
       " 'thisyoull',\n",
       " 'soothingly',\n",
       " 'thinguse',\n",
       " 'lieberman',\n",
       " 'hungers',\n",
       " 'justin',\n",
       " 'picnics',\n",
       " 'ancestors',\n",
       " 'august2008',\n",
       " 'turf',\n",
       " 'cosmo',\n",
       " 'nabisco',\n",
       " 'antinori',\n",
       " 'ruta',\n",
       " 'brood',\n",
       " 'yearwood',\n",
       " 'referred',\n",
       " 'du',\n",
       " 'specializes',\n",
       " 'addtion',\n",
       " 'seagulls',\n",
       " 'detected',\n",
       " 'manx',\n",
       " 'undetectable',\n",
       " 'seedless',\n",
       " 'pati',\n",
       " 'sutton',\n",
       " 'rinds',\n",
       " 'tableside',\n",
       " 'jif',\n",
       " 'primal',\n",
       " 'body',\n",
       " 'olla',\n",
       " 'lowcost',\n",
       " 'reach',\n",
       " 'bart',\n",
       " 'cooling',\n",
       " 'skyline',\n",
       " 'freezethawpress',\n",
       " 'bonbons',\n",
       " 'less',\n",
       " 'pediatrician',\n",
       " 'kunming',\n",
       " 'viskos',\n",
       " 'usborne',\n",
       " 'bad',\n",
       " 'raymondthick',\n",
       " 'baozi',\n",
       " 'ovenbroiling',\n",
       " 'searching',\n",
       " 'onequarter',\n",
       " 'melonorange',\n",
       " 'okd',\n",
       " 'him3',\n",
       " 'itself',\n",
       " 'skinless',\n",
       " '2year',\n",
       " 'casserolei',\n",
       " 'fairlylowcarbohydrate',\n",
       " 'wordsthe',\n",
       " 'lasagna',\n",
       " 'healthstyle',\n",
       " 'breadbiscuit',\n",
       " 'timeherb',\n",
       " 'lorna',\n",
       " 'ticked',\n",
       " 'breaky',\n",
       " 'fernandez',\n",
       " 'wonderbread',\n",
       " 'drinkcook',\n",
       " 'confectioners',\n",
       " 'easiness',\n",
       " 'different',\n",
       " 'tastessubmitted',\n",
       " 'underkoffler',\n",
       " 'grit',\n",
       " 'appetizerdip',\n",
       " 'kuhn',\n",
       " 'meatier',\n",
       " 'stewpot',\n",
       " 'dhespecially',\n",
       " 'transports',\n",
       " 'sacramento',\n",
       " 'mirliton',\n",
       " 'dayhas',\n",
       " 'winco',\n",
       " 'greenred',\n",
       " 'greater',\n",
       " 'c2007',\n",
       " 'kg',\n",
       " '10088',\n",
       " 'spaghetti',\n",
       " 'cookerwhere',\n",
       " 'noteblackberries',\n",
       " 'sitecoffee',\n",
       " 'anticancer',\n",
       " 'deliciouslycreamy',\n",
       " 'suffered',\n",
       " 'worlds',\n",
       " 'royer',\n",
       " '2004although',\n",
       " 'marry',\n",
       " 'mick',\n",
       " 'nowork',\n",
       " 'mirch',\n",
       " 'running',\n",
       " 'evidence',\n",
       " 'polished',\n",
       " 'saltines',\n",
       " '1997',\n",
       " 'fatper',\n",
       " 'gasthaus',\n",
       " '1942',\n",
       " '15yearold',\n",
       " 'splashing',\n",
       " 'sidewalk',\n",
       " 'mixologist',\n",
       " 'immitation',\n",
       " 'chicke',\n",
       " 'kai',\n",
       " 'itbut',\n",
       " 'distributors',\n",
       " 'marble',\n",
       " 'jacqus',\n",
       " 'hergrandmother',\n",
       " 'repackage',\n",
       " '400f',\n",
       " 'maragine',\n",
       " 'fairhaven',\n",
       " '133861',\n",
       " 'wier',\n",
       " 'granules',\n",
       " 'chimichuri',\n",
       " 'tubes',\n",
       " 'simplicity',\n",
       " 'bhgcom',\n",
       " 'coobeeon',\n",
       " 'throat',\n",
       " 'dz',\n",
       " 'tortieres',\n",
       " 'refreshment',\n",
       " 'friendsi',\n",
       " 'palomilla',\n",
       " 'kfcs',\n",
       " 'mainly',\n",
       " 'stoupits',\n",
       " '25gfiber',\n",
       " 'aarons',\n",
       " 'dark',\n",
       " 'padma',\n",
       " '7up',\n",
       " 'paranthas',\n",
       " 'hungarians',\n",
       " 'stephenson',\n",
       " 'year',\n",
       " 'mea',\n",
       " 'petite',\n",
       " 'pregrated',\n",
       " 'spencer',\n",
       " 'grapenut',\n",
       " 'foodthis',\n",
       " 'decision',\n",
       " '159188',\n",
       " 'frequent',\n",
       " 'soufle',\n",
       " 'raspberry',\n",
       " '06mg',\n",
       " 'uncookedfor',\n",
       " 'mustamakkara',\n",
       " 'anxious',\n",
       " 'royce',\n",
       " 'dallop',\n",
       " 'loukoumades',\n",
       " 'bananarum',\n",
       " 'socialise',\n",
       " 'hurst',\n",
       " 'moycullen',\n",
       " 'okras',\n",
       " 'computer',\n",
       " 'enhanced',\n",
       " 'shawn',\n",
       " 'wilfer',\n",
       " 'baptism',\n",
       " 'seatyou',\n",
       " 'recommened',\n",
       " 'versatilesprinkle',\n",
       " 'jellyroll',\n",
       " 'jan',\n",
       " 'drill',\n",
       " 'stickler',\n",
       " 'croque',\n",
       " 'beefcommon',\n",
       " 'lanark',\n",
       " 'festival',\n",
       " 'prefrozen',\n",
       " '812',\n",
       " 'hell',\n",
       " 'greekmacedonian',\n",
       " 'observer',\n",
       " 'noncooking',\n",
       " 'generous',\n",
       " 'gfcf',\n",
       " 'blackberry',\n",
       " 'tipschanges',\n",
       " 'wattage',\n",
       " 'copy',\n",
       " 'oden',\n",
       " 'namelebanon',\n",
       " 'anzac',\n",
       " 'invented',\n",
       " 'tyler',\n",
       " 'chrmla',\n",
       " '2000s',\n",
       " 'wimp',\n",
       " 'bartons',\n",
       " 'baconhoney',\n",
       " 'fisherman',\n",
       " 'thoughtlessly',\n",
       " 'tasteda',\n",
       " 'firehallchurch',\n",
       " 'tempeh',\n",
       " 'grampas',\n",
       " 'muthiyas',\n",
       " 'acquiring',\n",
       " 'bang',\n",
       " 'shipped',\n",
       " 'suger',\n",
       " '11am',\n",
       " 'peachnectarine',\n",
       " 'healthyand',\n",
       " 'starwberries',\n",
       " 'occupied',\n",
       " 'ending',\n",
       " 'chicks',\n",
       " 'asks',\n",
       " 'versus',\n",
       " 'marathon',\n",
       " 'workmen',\n",
       " 'rewritten',\n",
       " 'eatchickencom',\n",
       " 'agreed',\n",
       " 'beeps',\n",
       " 'tastyserve',\n",
       " 'precious',\n",
       " 'wheeler',\n",
       " 'leavened',\n",
       " 'colourfulprep',\n",
       " 'uncovers',\n",
       " 'romeos',\n",
       " 'overpoweringwe',\n",
       " '2006',\n",
       " 'verges',\n",
       " 'alongwith',\n",
       " 'sixhour',\n",
       " 'pattys',\n",
       " 'strikingly',\n",
       " 'hamersley',\n",
       " 'descriptions',\n",
       " 'goodprep',\n",
       " '332',\n",
       " 'privilege',\n",
       " 'goofed',\n",
       " 'stabilizes',\n",
       " '257',\n",
       " 'cayennefor',\n",
       " 'beefstew',\n",
       " 'sealer',\n",
       " 'asthma',\n",
       " 'moodtip',\n",
       " 'cocoa',\n",
       " 'tomatos',\n",
       " 'imagining',\n",
       " 'cheddar18',\n",
       " 'choices',\n",
       " 'cleansing',\n",
       " 'transform',\n",
       " 'lemonade',\n",
       " 'the2008',\n",
       " 'cobbler',\n",
       " 'httpwwwfoodcomreciperusticsourdoughfocacciawithcaramelizedonions67753',\n",
       " 'flavorsthese',\n",
       " 'falafel',\n",
       " 'silpats',\n",
       " 'effortless',\n",
       " '12lbs',\n",
       " 'often',\n",
       " 'donuts',\n",
       " 'rid',\n",
       " 'martinis',\n",
       " 'seinfield',\n",
       " 'simliar',\n",
       " 'step',\n",
       " 'daddy',\n",
       " 'chineseinspired',\n",
       " '61g',\n",
       " '1940',\n",
       " 'chickpea',\n",
       " 'offdry',\n",
       " '12oz',\n",
       " 'laced',\n",
       " 'deensiebat',\n",
       " 'guisada',\n",
       " 'amountsingredients',\n",
       " '7g',\n",
       " 'soup',\n",
       " 'mayone',\n",
       " 'christams',\n",
       " 'peppery',\n",
       " '41g',\n",
       " 'widerimmed',\n",
       " 'hesitate',\n",
       " 'greatestvery',\n",
       " 'richa',\n",
       " 'zwt6',\n",
       " 'witlof',\n",
       " 'ebbtide',\n",
       " 'gefilte',\n",
       " 'simpleand',\n",
       " 'soy',\n",
       " 'mcgavin',\n",
       " 'heavybottomed',\n",
       " 'bosc',\n",
       " 'avoids',\n",
       " '3to4',\n",
       " 'shaws',\n",
       " 'itguaranteed',\n",
       " 'keren',\n",
       " 'crunchies',\n",
       " 'handsqueeze',\n",
       " 'appetizersnack',\n",
       " 'saulles',\n",
       " 'simmered',\n",
       " 'chooks',\n",
       " 'oakland',\n",
       " 'gudrun',\n",
       " 'dayle',\n",
       " 'unsourced',\n",
       " 'boma',\n",
       " 'grillingbroiling',\n",
       " 'crumbs',\n",
       " 'boutique',\n",
       " '2009ive',\n",
       " 'onionchile',\n",
       " 'sauce',\n",
       " 'noodleshave',\n",
       " 'teaginseng',\n",
       " 'brunch',\n",
       " 'realised',\n",
       " 'mike',\n",
       " 'persists',\n",
       " 'dept',\n",
       " 'cubanasonia',\n",
       " 'giner',\n",
       " '315928',\n",
       " 'customs',\n",
       " 'pilma',\n",
       " 'almond',\n",
       " 'httpwwwrecipezaarcombbviewtopiczspt233992',\n",
       " 'hmmm',\n",
       " 'honeylemon',\n",
       " 'tail',\n",
       " 'nonexistent',\n",
       " 'trentino',\n",
       " 'distilled',\n",
       " 'handokay',\n",
       " 'despair',\n",
       " 'mcilhenny',\n",
       " 'aboutcomthe',\n",
       " 'likeputting',\n",
       " 'mushroomy',\n",
       " 'authenticyou',\n",
       " 'recreating',\n",
       " '27171',\n",
       " 'dayoriginally',\n",
       " 'fertig',\n",
       " 'judicial',\n",
       " 'benefit',\n",
       " 'daelemans',\n",
       " 'scans',\n",
       " 'scream',\n",
       " 'blandi',\n",
       " 'leagues',\n",
       " 'indefinite',\n",
       " 'adopting',\n",
       " 'kris',\n",
       " 'bloomin',\n",
       " 'grilland',\n",
       " 'rookie',\n",
       " 'cure',\n",
       " 'crackers',\n",
       " 'coolso',\n",
       " 'present',\n",
       " 'lebovitz',\n",
       " 'pits',\n",
       " 'isa',\n",
       " 'renal',\n",
       " 'phrase',\n",
       " 'talked',\n",
       " 'sift',\n",
       " 'farorite',\n",
       " 'toodys',\n",
       " 'tribune',\n",
       " 'bump',\n",
       " 'kicking',\n",
       " 'suh',\n",
       " 'appies',\n",
       " 'hampered',\n",
       " 'fussed',\n",
       " 'elisabeth',\n",
       " 'leaner',\n",
       " 'gutted',\n",
       " 'specht',\n",
       " 'healthiness',\n",
       " 'stewartmy',\n",
       " 'lusciousrich',\n",
       " 'entirely',\n",
       " 'drum',\n",
       " 'jersey',\n",
       " 'mellowed',\n",
       " 'nedium',\n",
       " 'redbook',\n",
       " 'nevertheless',\n",
       " 'bainmarie',\n",
       " 'xochimilco',\n",
       " 'guarded',\n",
       " 'foodive',\n",
       " 'culinary',\n",
       " 'loveand',\n",
       " 'bowties',\n",
       " 'afraid',\n",
       " 'boot',\n",
       " 'hills',\n",
       " '2002this',\n",
       " '67',\n",
       " 'trimmings',\n",
       " 'cashs',\n",
       " 'occasional',\n",
       " 'culinaary',\n",
       " 'badthis',\n",
       " 'shortbreadis',\n",
       " 'restaurant',\n",
       " 'mascarpone',\n",
       " 'purslane',\n",
       " 'generated',\n",
       " 'lettuceleaf',\n",
       " 'cookingforceliacs',\n",
       " 'vegetrian',\n",
       " 'oaks',\n",
       " 'neal',\n",
       " 'jaworski',\n",
       " 'hoard',\n",
       " 'chocolatepeanut',\n",
       " 'traded',\n",
       " 'peppersor',\n",
       " 'imperceptible',\n",
       " 'combonation',\n",
       " 'shrunk',\n",
       " 'ropa',\n",
       " 'regularsized',\n",
       " 'sallets',\n",
       " 'dairyland',\n",
       " 'oatmeal',\n",
       " 'delaurentiisfood',\n",
       " 'prechopped',\n",
       " 'piping',\n",
       " 'responds',\n",
       " 'slapdash',\n",
       " 'pomodoro',\n",
       " 'carmelized',\n",
       " 'leftoverbaked',\n",
       " 'crisco',\n",
       " 'replica',\n",
       " 'logan',\n",
       " '44614',\n",
       " 'metal',\n",
       " 'angolan',\n",
       " 'wayne',\n",
       " 'wwwkathycaseycomliquidkitchen',\n",
       " 'cakedont',\n",
       " 'era',\n",
       " 'explosion',\n",
       " 'elsalvidor',\n",
       " 'shanks',\n",
       " 'snuff',\n",
       " 'cody',\n",
       " 'shrimps',\n",
       " 'sugarbutter',\n",
       " 'tenderloin',\n",
       " '14oz',\n",
       " 'loosey',\n",
       " 'moulds',\n",
       " 'deepyou',\n",
       " 'august',\n",
       " 'chandra',\n",
       " '31110',\n",
       " 'potatoesgo',\n",
       " 'prunes',\n",
       " 'rumford',\n",
       " 'milki',\n",
       " 'biscotti',\n",
       " 'pyrophosphate',\n",
       " 'exterior',\n",
       " 'patios',\n",
       " 'topa',\n",
       " 'brickred',\n",
       " '88991',\n",
       " 'marrying',\n",
       " 'potatoesenjoy',\n",
       " 'httpwwwrecipezaarcompineappleupsidedowncake408537',\n",
       " 'foreman',\n",
       " 'mints',\n",
       " 'food52com',\n",
       " 'grassroots',\n",
       " 'dallasnewscom',\n",
       " 'eggsbut',\n",
       " 'bbqparty',\n",
       " 'bratwurst',\n",
       " 'shocked',\n",
       " 'stash',\n",
       " 'meati',\n",
       " 'indie',\n",
       " 'cellophane',\n",
       " 'bacon',\n",
       " 'kofta',\n",
       " 'andree',\n",
       " 'fails',\n",
       " 'horizontally',\n",
       " 'supports',\n",
       " 'chefscom',\n",
       " 'pia',\n",
       " 'quesadilla',\n",
       " '132',\n",
       " 'lamisons',\n",
       " 'darken',\n",
       " 'sort',\n",
       " 'bocconcini',\n",
       " 'respiratory',\n",
       " 'aesthetically',\n",
       " 'thriceor',\n",
       " 'swift',\n",
       " 'brin',\n",
       " 'lfrv',\n",
       " 'birdseye',\n",
       " 'cheeseadd',\n",
       " 'good071908',\n",
       " 'provide',\n",
       " 'seventy',\n",
       " 'handcrank',\n",
       " 'rehab',\n",
       " 'soldjicama',\n",
       " 'bitterness',\n",
       " 'vine',\n",
       " 'presence',\n",
       " 'bros',\n",
       " 'inch',\n",
       " 'neighboring',\n",
       " 'willingly',\n",
       " 'maximum',\n",
       " 'yk',\n",
       " 'bakethen',\n",
       " 'thee',\n",
       " 'workmate',\n",
       " 'robens',\n",
       " 'febmar',\n",
       " 'likea',\n",
       " 'cakeso',\n",
       " 'kurihara',\n",
       " 'orig',\n",
       " 'koolaid',\n",
       " 'clay',\n",
       " 'potatoeshope',\n",
       " 'unpleasant',\n",
       " 'pricey',\n",
       " 'lisbon',\n",
       " 'bol',\n",
       " 'incorporates',\n",
       " 'liquefied',\n",
       " 'fathom',\n",
       " 'rehydrated',\n",
       " 'kvor',\n",
       " 'favorably',\n",
       " 'kashmiri',\n",
       " 'hindi',\n",
       " 'bouillon',\n",
       " 'sustained',\n",
       " 'loosen',\n",
       " 'heatters',\n",
       " '23s',\n",
       " 'dag',\n",
       " 'halloweenfall',\n",
       " 'levana',\n",
       " '1526',\n",
       " 'vatiety',\n",
       " 'asiago',\n",
       " 'mckenna',\n",
       " 'macaroni',\n",
       " 'wwwtiendacom',\n",
       " 'reappearing',\n",
       " 'parma',\n",
       " '1007',\n",
       " 'juiceprep',\n",
       " 'etceasy',\n",
       " 'gnudi',\n",
       " 'campoutwrapped',\n",
       " 'glue',\n",
       " 'christmasa',\n",
       " 'apr',\n",
       " 'possibility',\n",
       " 'milkfree',\n",
       " 'virtue',\n",
       " 'enjoyi',\n",
       " 'lb',\n",
       " 'shepards',\n",
       " 'delectably',\n",
       " 'monisha',\n",
       " 'cathi',\n",
       " 'chatelaine',\n",
       " '141048',\n",
       " 'mayo',\n",
       " 'dizzy',\n",
       " 'egypts',\n",
       " 'jumbled',\n",
       " 'clinic',\n",
       " 'calender',\n",
       " 'chillo',\n",
       " 'hogging',\n",
       " 'lantana',\n",
       " 'tommy',\n",
       " 'retention',\n",
       " 'flaxseeds',\n",
       " 'em',\n",
       " 'knobbly',\n",
       " 'suggests',\n",
       " 'failing',\n",
       " 'silken',\n",
       " 'sisiters',\n",
       " 'capsicums',\n",
       " 'grapefruits',\n",
       " 'cheesyherb',\n",
       " 'mccartneys',\n",
       " 'iti',\n",
       " 'swear',\n",
       " 'slicer',\n",
       " 'vines',\n",
       " 'softandcakelike',\n",
       " 'halfway',\n",
       " 'chapman',\n",
       " 'usethe',\n",
       " 'doz',\n",
       " 'pides',\n",
       " 'menthe',\n",
       " 'feeling',\n",
       " 'unmoulding',\n",
       " '6',\n",
       " 'dressings',\n",
       " 'bay',\n",
       " 'spritzer',\n",
       " 'saladsthis',\n",
       " 'wows',\n",
       " 'anythingthis',\n",
       " 'shroooms',\n",
       " 'burritosize',\n",
       " 'myselfsince',\n",
       " 'strong',\n",
       " 'trouble',\n",
       " 'bayinfused',\n",
       " 'runnier',\n",
       " 'httplifestylemsncomfoodandentertainingrecipesarticlebhgaspxcpdocumentid7084588i',\n",
       " 'munchies',\n",
       " 'richest',\n",
       " 'bluesand',\n",
       " 'clamoring',\n",
       " 'recipeingredients',\n",
       " 'combinationnote2',\n",
       " 'rogies',\n",
       " 'riddled',\n",
       " 'kongstyle',\n",
       " 'twocrust',\n",
       " '28mg',\n",
       " 'mincooking',\n",
       " 'anoter',\n",
       " 'mousse',\n",
       " 'concentration',\n",
       " 'nprs',\n",
       " 'yumwho',\n",
       " 'icelanders',\n",
       " 'rodriguez',\n",
       " 'due',\n",
       " 'germain',\n",
       " 'harvard',\n",
       " 'tastemore',\n",
       " 'grosserode',\n",
       " '23x',\n",
       " 'mixup',\n",
       " 'compulsory',\n",
       " 'tombs',\n",
       " 'claycamp',\n",
       " 'chickencornish',\n",
       " 'turner',\n",
       " 'kato',\n",
       " 'grudgingly',\n",
       " 'slighly',\n",
       " 'extraordinarily',\n",
       " 'sitehttpwwwnikibonecomrecipeveganvegantourtierehtm',\n",
       " 'elaine',\n",
       " '356853',\n",
       " 'christmass',\n",
       " 'suffers',\n",
       " 'recipegoldmineupdate',\n",
       " '463563',\n",
       " 'eating',\n",
       " 'wheel',\n",
       " 'nowasmith',\n",
       " '325f',\n",
       " 'usedif',\n",
       " 'zwt9wwwtheperfectpantrycom',\n",
       " 'mennonites',\n",
       " 'gingery',\n",
       " 'recipewiki',\n",
       " 'somehow',\n",
       " 'sales',\n",
       " 'pret',\n",
       " 'splendas',\n",
       " 'chilinice',\n",
       " 'vendorgrowers',\n",
       " '2011i',\n",
       " 'poohanpiglet',\n",
       " 'if',\n",
       " 'conquest',\n",
       " 'partake',\n",
       " 'someplace',\n",
       " 'breathtaking',\n",
       " 'mania',\n",
       " 'dealer',\n",
       " 'cheeseits',\n",
       " 'seasonally',\n",
       " 'gist',\n",
       " '1872fat',\n",
       " 'moonmaking',\n",
       " 'tat',\n",
       " 'livejournal',\n",
       " 'island',\n",
       " 'aidells',\n",
       " 'gourmetrecipesfromaroundthe',\n",
       " 'masked',\n",
       " 'recipesive',\n",
       " 'fullerton',\n",
       " 'manis',\n",
       " 'addicting',\n",
       " 'casey',\n",
       " 'omac',\n",
       " 'cabot',\n",
       " 'upor',\n",
       " 'wit',\n",
       " 'stephan',\n",
       " 'honeymixer',\n",
       " 'hamtramck',\n",
       " 'traces',\n",
       " 'trusty',\n",
       " 'foodmeatloaf',\n",
       " '209247',\n",
       " 'figs',\n",
       " 'meaning',\n",
       " 'crockerthis',\n",
       " 'goodim',\n",
       " 'flavorsthe',\n",
       " 'vanillaenjoy',\n",
       " 'hawk',\n",
       " 'combinationnot',\n",
       " 'cookerwhile',\n",
       " 'earthenware',\n",
       " 'francesca',\n",
       " 'perferably',\n",
       " 'damsons',\n",
       " 'seviche',\n",
       " 'lori',\n",
       " 'galncmysteryshopper',\n",
       " 'alaskan',\n",
       " 'blogs',\n",
       " 'valencia',\n",
       " 'tunnel',\n",
       " 'prickly',\n",
       " 'christi',\n",
       " 'blogspotcom',\n",
       " '2025',\n",
       " 'questioning',\n",
       " 'fritz',\n",
       " 'unwashed',\n",
       " 'snowy',\n",
       " 'chickenshe',\n",
       " 'session',\n",
       " 'someoness',\n",
       " 'homesgardens',\n",
       " 'drew',\n",
       " 'once',\n",
       " 'halving',\n",
       " 'nostalgia',\n",
       " 'pear',\n",
       " 'squeak',\n",
       " 'nugget',\n",
       " '12th05',\n",
       " 'frustrating',\n",
       " 'deter',\n",
       " 'frostingfat',\n",
       " 'selfhelp',\n",
       " 'ulcer1',\n",
       " 'descriptionserve',\n",
       " 'guava',\n",
       " 'cardinals',\n",
       " 'samp',\n",
       " 'bastianichs',\n",
       " 'coladas',\n",
       " 'jazzes',\n",
       " 'considerable',\n",
       " 'bucatini',\n",
       " 'itchyenjoy',\n",
       " 'navelthough',\n",
       " '118894',\n",
       " 'refreshingly',\n",
       " 'matteri',\n",
       " '7switzerland',\n",
       " 'bugged',\n",
       " 'quisine',\n",
       " 'bowersox',\n",
       " 'copykatcomhttpwwwcopykatcom',\n",
       " 'pampered',\n",
       " 'towelling',\n",
       " 'porkchops',\n",
       " 'consist',\n",
       " 'towards',\n",
       " 'breadsrecipe',\n",
       " 'shii',\n",
       " 'themes',\n",
       " 'nira',\n",
       " 'shortens',\n",
       " 'perking',\n",
       " 'rotten',\n",
       " 'indentation',\n",
       " 'grandparentscom',\n",
       " 'juicegravy',\n",
       " 'fooi',\n",
       " 'tubular',\n",
       " 'passive',\n",
       " 'publisher',\n",
       " 'your',\n",
       " 'pristinely',\n",
       " '104',\n",
       " 'mixers',\n",
       " '163426',\n",
       " 'modesty',\n",
       " 'skills',\n",
       " 'peachespearsor',\n",
       " 'caserra',\n",
       " 'magazineso',\n",
       " 'preferencesonly',\n",
       " 'claytons',\n",
       " 'sinfully',\n",
       " 'jeannes',\n",
       " 'unit',\n",
       " 'adjustmentsyou',\n",
       " '221637',\n",
       " 'kwahee',\n",
       " 'human',\n",
       " 'venturing',\n",
       " 'searve',\n",
       " 'undercooked',\n",
       " 'trendy',\n",
       " 'barrel',\n",
       " 'stampsholds',\n",
       " 'faviorite',\n",
       " 'beautifuly',\n",
       " 'frufru',\n",
       " 'notice',\n",
       " 'dividing',\n",
       " 'teton',\n",
       " 'oilit',\n",
       " 'luncheshope',\n",
       " 'foodie',\n",
       " 'methis',\n",
       " 'obtain',\n",
       " 'reposting',\n",
       " 'duncans',\n",
       " '56g',\n",
       " 'caravan',\n",
       " 'hyveecom',\n",
       " '38',\n",
       " 'cool',\n",
       " 'aprilmay',\n",
       " 'gur',\n",
       " 'loureno',\n",
       " 'quickandeasy',\n",
       " 'kirchner',\n",
       " 'scarfed',\n",
       " 'pops',\n",
       " 'quanities',\n",
       " 'butterhorns',\n",
       " 'jefes',\n",
       " 'benifits',\n",
       " 'mornings',\n",
       " 'sink',\n",
       " 'limb',\n",
       " 'cakebeing',\n",
       " 'bbqed',\n",
       " 'dishes',\n",
       " 'wonder',\n",
       " 'chemotherapy',\n",
       " 'ethnic',\n",
       " 'nowi',\n",
       " 'surprised',\n",
       " 'additinal',\n",
       " 'earthbound',\n",
       " 'places1',\n",
       " 'franklin',\n",
       " 'feet',\n",
       " 'value',\n",
       " 'donairs',\n",
       " 'employer',\n",
       " 'guyana',\n",
       " 'rollup',\n",
       " 'ithehe',\n",
       " 'wrinkled',\n",
       " 'garnished',\n",
       " 'kvass',\n",
       " 'loveseven',\n",
       " 'goffewoods',\n",
       " 'elaborately',\n",
       " 'corkscrew',\n",
       " 'sandison',\n",
       " 'necessity',\n",
       " 'exchanged',\n",
       " '2030',\n",
       " 'countdown',\n",
       " 'luminous',\n",
       " 'carney',\n",
       " 'f0r',\n",
       " 'toppingthis',\n",
       " '250265',\n",
       " 'capersthis',\n",
       " 'crackerscook',\n",
       " 'starchier',\n",
       " 'publishers',\n",
       " 'danube',\n",
       " 'diningulterior',\n",
       " 'impression',\n",
       " 'swiss',\n",
       " 'houswarming',\n",
       " 'nicknames',\n",
       " '230939',\n",
       " ...}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words = set()\n",
    "for i in df['preprocessed_descriptions'].values:\n",
    "    words.update(word_tokenize(str(i).lower()))\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. crowds   & blood    : расстояние между ними 4\n",
      "2. google   & regis    : расстояние между ними 5\n",
      "3. fiddling & 1890s    : расстояние между ними 8\n",
      "4. neat     & followers: расстояние между ними 8\n",
      "5. chest    & prisoners: расстояние между ними 8\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "import random\n",
    "word1 = random.choices(list(words), k=5)\n",
    "word2 = random.choices(list(words - set(word1)), k=5)\n",
    "pair = zip(word1, word2) \n",
    "for index, (k, v) in enumerate(pair):\n",
    "    print(f\"{index+1}. {k:<{max(map(len, word1))}} & {v:<{max(map(len, word2))}}: расстояние между ними {edit_distance(k, v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest(word, k):\n",
    "    wlist = list(words)\n",
    "    wsorted = sorted(enumerate(map(lambda x: edit_distance(word, x), wlist)), key = lambda x: x[1])\n",
    "    res = list(map(lambda x: (wlist[x[0]],x[1]), wsorted[:k]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', 0), ('hell', 1), ('mello', 1), ('jello', 1), ('hills', 2)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest('hello', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>devis</th>\n",
       "      <td>devi</td>\n",
       "      <td>devi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mircaz</th>\n",
       "      <td>mircaz</td>\n",
       "      <td>mircaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ortegas</th>\n",
       "      <td>ortega</td>\n",
       "      <td>ortega</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232706</th>\n",
       "      <td>232706</td>\n",
       "      <td>232706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liners</th>\n",
       "      <td>liner</td>\n",
       "      <td>liner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75548</th>\n",
       "      <td>75548</td>\n",
       "      <td>75548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overindulging</th>\n",
       "      <td>overindulg</td>\n",
       "      <td>overindulging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employees</th>\n",
       "      <td>employe</td>\n",
       "      <td>employee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yucca</th>\n",
       "      <td>yucca</td>\n",
       "      <td>yucca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mostess</th>\n",
       "      <td>mostess</td>\n",
       "      <td>mostess</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              stemmed_word normalized_word\n",
       "devis                 devi            devi\n",
       "mircaz              mircaz          mircaz\n",
       "ortegas             ortega          ortega\n",
       "232706              232706          232706\n",
       "liners               liner           liner\n",
       "...                    ...             ...\n",
       "75548                75548           75548\n",
       "overindulging   overindulg   overindulging\n",
       "employees          employe        employee\n",
       "yucca                yucca           yucca\n",
       "mostess            mostess         mostess\n",
       "\n",
       "[32868 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "stem = SnowballStemmer('english')\n",
    "wlist = list(words)\n",
    "words_df = pd.DataFrame(dict(stemmed_word=map(stem.stem, wlist), normalized_word=map(wnl.lemmatize, wlist)), index = wlist)\n",
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "      <th>edit_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>devis</th>\n",
       "      <td>devi</td>\n",
       "      <td>devi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mircaz</th>\n",
       "      <td>mircaz</td>\n",
       "      <td>mircaz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ortegas</th>\n",
       "      <td>ortega</td>\n",
       "      <td>ortega</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232706</th>\n",
       "      <td>232706</td>\n",
       "      <td>232706</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liners</th>\n",
       "      <td>liner</td>\n",
       "      <td>liner</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75548</th>\n",
       "      <td>75548</td>\n",
       "      <td>75548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overindulging</th>\n",
       "      <td>overindulg</td>\n",
       "      <td>overindulging</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employees</th>\n",
       "      <td>employe</td>\n",
       "      <td>employee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yucca</th>\n",
       "      <td>yucca</td>\n",
       "      <td>yucca</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mostess</th>\n",
       "      <td>mostess</td>\n",
       "      <td>mostess</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              stemmed_word normalized_word  edit_distance\n",
       "devis                 devi            devi              0\n",
       "mircaz              mircaz          mircaz              0\n",
       "ortegas             ortega          ortega              0\n",
       "232706              232706          232706              0\n",
       "liners               liner           liner              0\n",
       "...                    ...             ...            ...\n",
       "75548                75548           75548              0\n",
       "overindulging   overindulg   overindulging              3\n",
       "employees          employe        employee              1\n",
       "yucca                yucca           yucca              0\n",
       "mostess            mostess         mostess              0\n",
       "\n",
       "[32868 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#сравниваем\n",
    "words_df['edit_distance'] = words_df.apply(lambda x: edit_distance(x.stemmed_word, x.normalized_word), axis=1)\n",
    "words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1069885"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for i in df.preprocessed_descriptions:\n",
    "    counter.update(word_tokenize(str(i).lower()))\n",
    "n_words_old = sum(counter.values()); n_words_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 40072),\n",
       " ('a', 34951),\n",
       " ('and', 30245),\n",
       " ('this', 26859),\n",
       " ('i', 24836),\n",
       " ('to', 23471),\n",
       " ('is', 20285),\n",
       " ('it', 19756),\n",
       " ('of', 18364),\n",
       " ('for', 15939)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Топ 10 употребляемых слов до очистки\n",
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Стоп слова составляли 54.4% от общего числа слов\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "keys = list(counter.keys())\n",
    "for i in keys:\n",
    "    if i in en_stopwords:\n",
    "        counter.pop(i)\n",
    "print(f'Стоп слова составляли {round(sum(counter.values()) / n_words_old * 100, 1)}% от общего числа слов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('recipe', 14871),\n",
       " ('make', 6326),\n",
       " ('time', 5137),\n",
       " ('use', 4620),\n",
       " ('great', 4430),\n",
       " ('like', 4167),\n",
       " ('easy', 4152),\n",
       " ('one', 3872),\n",
       " ('made', 3810),\n",
       " ('good', 3791)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Топ 10 употребляемых слов после очистки\n",
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.24298892, 0.        , 0.        ,\n",
       "       0.        , 0.13689572, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.19604193,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.24298892,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.13689572, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.24298892, 0.        ,\n",
       "       0.        , 0.        , 0.19604193, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.24298892, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.24298892,\n",
       "       0.        , 0.        , 0.24298892, 0.48597784, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.24298892, 0.        , 0.24298892, 0.        , 0.24298892,\n",
       "       0.24298892, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.24298892, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "sample = df.sample(5)\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(sample.preprocessed_descriptions.values).toarray()\n",
    "\n",
    "#Например 2 вектор\n",
    "vectors[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>easy potato rolls</th>\n",
       "      <th>danish holiday fruit soup  sdsuppe</th>\n",
       "      <th>lime pepper</th>\n",
       "      <th>sausage  pepper and egg heros</th>\n",
       "      <th>easy 5 ingredient vegetable lasagna</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>easy potato rolls</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936350</td>\n",
       "      <td>0.851779</td>\n",
       "      <td>0.936617</td>\n",
       "      <td>0.959358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danish holiday fruit soup  sdsuppe</th>\n",
       "      <td>0.936350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.889790</td>\n",
       "      <td>0.981338</td>\n",
       "      <td>0.926987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lime pepper</th>\n",
       "      <td>0.851779</td>\n",
       "      <td>0.889790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.881829</td>\n",
       "      <td>0.896007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sausage  pepper and egg heros</th>\n",
       "      <td>0.936617</td>\n",
       "      <td>0.981338</td>\n",
       "      <td>0.881829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.908815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy 5 ingredient vegetable lasagna</th>\n",
       "      <td>0.959358</td>\n",
       "      <td>0.926987</td>\n",
       "      <td>0.896007</td>\n",
       "      <td>0.908815</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     easy potato rolls  \\\n",
       "name                                                     \n",
       "easy potato rolls                             0.000000   \n",
       "danish holiday fruit soup  sdsuppe            0.936350   \n",
       "lime pepper                                   0.851779   \n",
       "sausage  pepper and egg heros                 0.936617   \n",
       "easy 5 ingredient vegetable lasagna           0.959358   \n",
       "\n",
       "                                     danish holiday fruit soup  sdsuppe  \\\n",
       "name                                                                      \n",
       "easy potato rolls                                              0.936350   \n",
       "danish holiday fruit soup  sdsuppe                             0.000000   \n",
       "lime pepper                                                    0.889790   \n",
       "sausage  pepper and egg heros                                  0.981338   \n",
       "easy 5 ingredient vegetable lasagna                            0.926987   \n",
       "\n",
       "                                     lime pepper  \\\n",
       "name                                               \n",
       "easy potato rolls                       0.851779   \n",
       "danish holiday fruit soup  sdsuppe      0.889790   \n",
       "lime pepper                             0.000000   \n",
       "sausage  pepper and egg heros           0.881829   \n",
       "easy 5 ingredient vegetable lasagna     0.896007   \n",
       "\n",
       "                                     sausage  pepper and egg heros  \\\n",
       "name                                                                 \n",
       "easy potato rolls                                         0.936617   \n",
       "danish holiday fruit soup  sdsuppe                        0.981338   \n",
       "lime pepper                                               0.881829   \n",
       "sausage  pepper and egg heros                             0.000000   \n",
       "easy 5 ingredient vegetable lasagna                       0.908815   \n",
       "\n",
       "                                     easy 5 ingredient vegetable lasagna  \n",
       "name                                                                      \n",
       "easy potato rolls                                               0.959358  \n",
       "danish holiday fruit soup  sdsuppe                              0.926987  \n",
       "lime pepper                                                     0.896007  \n",
       "sausage  pepper and egg heros                                   0.908815  \n",
       "easy 5 ingredient vegetable lasagna                             0.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "matrix = pd.DataFrame({i:[cosine(vectors[index], vectors[index2]) for index2, k in enumerate(sample.name)] for index,i in enumerate(sample.name)}, index=sample.name)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее похожие рецепты: \n",
      "1)danish holiday fruit soup  sdsuppe\n",
      "2)sausage  pepper and egg heros\n",
      " Расстрояние между ними равно: 0.9813382550482084\n"
     ]
    }
   ],
   "source": [
    "row_max, row_index = matrix.values.max(axis=1), matrix.values.argmax(axis=1)\n",
    "col_max, col_index = max(row_max), np.argmax(row_max)\n",
    "\n",
    "print(f'Наиболее похожие рецепты: \\n1){matrix.columns[col_index]}\\n2){matrix.index.values[row_index][col_index]}\\n Расстрояние между ними равно: {col_max}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
